---
###############
# DO NOT EDIT
layout: proposal
###############

###############
# TO EDIT
# pub title
title: "Data-Driven Navigation Assistance"

# publication image
image:
 name: smartphone-sensors.jpeg
 alt-text: "A person holding a smartphone and pointing its camera to a building." # provide a short description for the image #a11y

# short description of the publication
motivation: "People with vision impairments are able to navigate independently by using their Orientation and Mobility skills and their travel aids - white cane or guide dog. However, navigating independently in unfamiliar and/or complex locations is still a main challenge and therefore blind people are often assisted by sighted people in such scenarios. While navigation technologies such as those based on GPS (e.g., Google Maps) can help, their accuracy is still too low (e.g., around 5 meters) to fully support blind users when navigating in unknown locations. On the other hand, indoor locations do not support GPS and generally do not have a navigation system installed."

work: "Our goal is to use data from the crowd (other people who walked the same areas before) to learn more about the environment and be able to provide additional instructions to blind users. A possible approach is to use smartphone sensors to estimate possible paths after an individual enters a building. While the GPS may inform us that users are entering/inside a building, large amounts of data (crowd-based) from smartphone sensors may give us information about possible paths and obstacles to instruct blind users. For instance, one may learn that after the entrance there is a path going left and after approximately 10 meters there are stairs to go up one floor; and another path that goes forward (and so on). While the data from a single user may be erroneous, we plan to use data from many users to make such an approach more robust."

# people associated with the publication
people:
 - jpvg
 - jc

###
---
